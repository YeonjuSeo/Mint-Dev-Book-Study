Chap 1. 한눈에 보는 머신러닝
============================  
머신러닝이란?  
-------------
(일반적)특정 프로그램 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야  
(공학적)어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을때 경험 E로 인해 성능이 향상되었다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.

머신러닝을 사용하는 이유
------------------
__전통적인 프로그래밍 기법과 머신러닝을 비교하면 머신러닝을 사용하는 이유를 두드러지게 알 수 있다.__  
스팸 필터 만들기(스팸필터 : 스팸메세지를 자동적으로 삭제해주는 프로그램)를 통해 비교해보겠다.  
* 전통적인 프로그래밍 기법  
``` 
1. 스팸에 어떤 단어들이 주로 나타나는지 살펴본다. -> 스팸메세지의 패턴을 찾아낸다.
2. 발견한 각 패턴을 감지하는 알고리즘을 작성하여 해당 패턴을 찾아냈을때 그 메일을 스팸으로 분류하게 한다.
3. 프로그램을 테스트하고 론칭할 만큼 충분한 성능이 나올 때까지 1, 2단계 반복
```
=> 문제가 이렇게 어려운 경우엔 규칙이 길고 복잡해지므로 유지 보수하기 힘들어진다.  
=> 스팸 메일 발송자가 스팸 필터에 대항하여 단어를 조금씩 바꾼다면 새로운 규칙을 매번 추가해야 한다.

* 머신러닝 기법
```
스팸에 자주 나타나는 패턴을 감지하여 어떤 단어와 구절이 스팸 메일을 판단하는데 좋은 기준인지 자동으로 학습한다. 
```
=> 프로그램이 훨씬 짧아지고 유지 보수하기 쉬우며, 정확도도 높다.  
=> 스팸 메일 발송자가 단어를 조금씩 바꾸어 발송한다 하더라도 해당 패턴을 다시 자동으로 인식하고 스팸으로 분류해준다.

__또한 머신러닝은 전통적인 방식으로는 너무 복잡하거나 알려진 알고리즘이 없는 문제에 유용하다.(음성 인식 같은 복잡한 문제에 적합하다)__

__또한 머신러닝을 통해 대용량의 데이터의 패턴을 발견할 수도 있다.(데이터 마이닝)__


머신러닝 시스템의 종류
-------
* 학습하는 동안의 감독 형태에 따라
  + 지도 학습  
    훈련 데이터에 레이블이라는 원하는 답을 포함된다. 레이블이 있으므로 어떤 인풋을 ML모델으로 돌렸을때 아웃풋이 그것에 해당하는 특정 레이블로 나온다.  
    __분류__(ex. 스팸 필터), __회귀__(데이터를 통해 회귀식을 만들어 특정 변수에 해당하는 값을 결과 낼 수 있음)등이 전형적인 지도 학습 작업이다.
  + 비지도 학습  
    훈련 데이터에 레이블이 포함되지 않는다. 레이블이 없어 내부적인 것(감지한 패턴 등)에 초점을 맞출때 사용된다.   
    __군집__(비슷한 데이터끼리 그룹으로 묶음), __시각화__(고차원 데이터를 학습하여 도식화가 가능한 2D나 3D 표현을 만들어줌), __차원 축소__(상관관계가 있는 여러 특성을 하나로 합쳐 데이터를 간소화/ 특성 추출),
     __이상치 감지__, __연관 규칙 학습__(데이터에서 특성 간의 어떤 관계를 찾음)등이 전형적인 비지도 학습 작업이다. 
  + 준지도 학습  
    일부만 레이블이 있는 데이터를 다루는 학습(데이터에 레이블을 다는 것은 비용이 많이 들기 때문에 레이블된 샘플이 더 적은 경우가 많음)  
    __심층 신뢰 신경망__(RBM이 비지도 학습 방식으로 순차적으로 훈련된 후 전체 시스템이 지도 학습 방식으로 세밀하게 조정됨)등이 전형적인 준지도 학습 작업이다.  
  + 강화 학습  
    환경을 관찰해서 행동으로 실행하고 그 결과로 보상을 받는 모델이다. 시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습한다.  
    __보행 로봇__만드는데 많이 사용되며, 구글 딥마인드 사의 알파고도 강화학습을 사용하여 만들었다.  
* 점진적으로 학습할 수 있는지의 여부에 따라  
  + 배치 학습(오프라인 학습)  
    시스템이 점진적으로 학습할 수 없다.   
    시스템을 훈련시키고 제품 시스템에 적용하면 더 이상의 학습없이 실행된다. (학습한 것을 단지 적용만 한다.)  
    새로운 데이터에 적응하려면 전체 데이터(새로운 데이터 + 이전 데이터)를 사용하여 처음부터 다시 훈련해야 한다. (이렇게 만들어진 시스템은 새로운 시스템이 된다.)  
    데이터를 업데이트하고 시스템의 새 버전을 필요한 만큼 자주 훈련시키면 변화에 쉽게 적응할 수 있다.  
    => 비교적 능동적인 데이터에 적합하지 않고, 많은 컴퓨팅 자원이 필요하여 데이터 양이 아주 많으면 배치 학습 알고리즘 사용이 불가할 수 있다.  
  + 온라인 학습(점진적 학습)  
    데이터를 순차적으로 한 개씩 혹은 미니배치라 부르는 작은 묶음 단위로 시스템을 훈련시킨다.  
    매 학습 단계가 빠르고 배용이 적게 들어 데이터가 도착하는 대로 즉시 학습할 수 있다. (학습이 끝난 데이터는 버려도 되므로 비용이 적게 든다.)  
    => 빠른 변화에 스스로 적응해야 하는 시스템에 적합하고 외부 메모리 학습(아주 큰 데이터셋를 학습하는 시스템)에도 사용할 수 있다.  
    => 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소한다.  
* 일반화 방법에 따라(새로운 데이터에서 좋은 예측을 만들기 위한 방법에 따라)  
  + 사례 기반 학습    
    훈련 샘플을 통해 유사도를 측정하고 새로운 데이터와 학습한 샘플을 비교하여 일반화한다.  
  + 모델 기반 학습  
    훈련 샘플들의 모델을 만들어 일반화한다.  
    모델을 선택하고 모델을 학습한 후 만든 모델을 사용해 예측한다.  

머신러닝의 문제가 되는 요소
---
* 나쁜 데이터  
  + 충분하지 않은 양의 데이터  
    샘플이 작으면 샘플링 잡음이 발생할 수 있다.  
    여러 다른 머신러닝 알고리즘에 충분한 양의 데이터가 주어지면 복잡한 자연어 중의성 해소 문제를 거의 비슷하게 잘 처리할 수 있다라는 것이 밝혀졌다.  
    (복잡한 문제에서 알고리즘보다 데이터가 더 중요하다)  
  + 대표성이 없는 훈련 데이터  
    매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띄지 못할 수 있다.(샘플링 편향)  
  + 낮은 품질의 데이터  
    훈련 데이터가 에러, 이상치, 잡음으로 가득한 경우 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것이다.  
    => 훈련 데이터를 정제해야한다.  
    일부 샘플이 이상치인 경우 혹은 일부 샘플에 특성 몇 개가 빠져있는 경우 훈련 데이터를 정제해야한다.  
  + 관련없는 특성  
    성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것이다.(__특성 공학__)
      - 특성 선택 : 가진 특성 중 훈련에 가장 유용한 특성을 선택
      - 특성 추출 : 특성을 결합하여 더 유용한 특성을 만듦(차원 축소,..)
      - 새로운 데이터를 수집해 새 특성을 만듦
* 나쁜 알고리즘  
  + 훈련 데이터 과대 적합  
    모델이 훈련 데이터에만 너무 잘 맞아, 일반성을 떨어지는 경우를 말한다.  
    __규제__ : 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가함.
    학습하는 동안 적용할 규제의 양은 하이퍼파라미터가 결정한다. 하이퍼파라미터는 학습 알고리즘의 파라미터로써, 값이 크면 기울기가 0에 가까운 거의 편평한 모델을 얻게 된다. 
  + 훈련 데이터 과소 적합  
    과대 적합과 반대로 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다.  
    모델 파라미터가 더 강력한 모델을 선택하거나, 학습 알고리즘에 더 좋은 측성을 제공하거나, 모델의 제약을 줄임으로써 해결할 수 있다.  
   
테스트와 검증
---
모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법은 새로운 샘플에 실제로 적용해 보는 것이다.  
보통 훈련 데이터를 훈련 세트와 테스트 세트 두 개로 나누어 훈련, 테스트한다.  
새로운 샘플에 대한 오류 비율을 일반화 오차라고 하며, 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값을 얻는다.  

테스트 시에, 일반화 오차를 테스트 세트에서 여러 번 측정하므로 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만들어 훈련 오차, 일반화 오차가 낮은데도 실제로 오차가 많이 나올 수 있다.   
이 경우 일반적으로 __홀드아웃 검증__을 이용하려 해결한다.  
```
홀드아웃 검증  
1. 훈련 세트의 일부를 떼어내어(검증 세트) 여러 후보 모델을 평가하고 가장 좋은 하나를 선택하고  
2. 줄어든 훈련 세트(검증 세트가 제외된 훈련 세트)에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련한다.  
3. 그 중에서 가장 높은 성능을 내는 모델을 선택한다. 
```
홀드아웃 검증 과정이 끝나면 선택한 모델을 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만들고 테스트 세트에서 평가하여 일반화 오차를 추정한다.  
이 방법은 일반적으로 잘 작동하나 검증 세트가 너무 작거나 크면 정확도가 떨어진다. 검증 세트가 매우 크면 남은 훈련 세트가 작아지기 때문에 좋지 않다.  

__어떤 모델이 최선인지 확실히 아는 유일한 방법은 모든 모델을 평가해 보는 것뿐이지만 이는 불가능하기 때문에 실전에서는 데이터에 관해 타당한 가정을 하고 적절한 모델 몇 가지만 평가한다.__  


